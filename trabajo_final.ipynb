{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosas ha hacer: ##\n",
    "1. Integracion: \n",
    "    - Obtención de datos: OK\n",
    "    - Explicación del dataset: OK\n",
    "    - Resolver duplicidades e incosistencias. \n",
    "    - Resolver problemas de codificacion (unidades de medida Km, m).\n",
    "2. Preprocesamiento:\n",
    "    - Outliers: OK.\n",
    "    - Valores faltantes: OK.(Obtener por la mediana o por algun metodo REV).\n",
    "    - Normalizar: No es necesario ya que con el tratamiento de los outliers los valores son manejables.\n",
    "    - Discretizar\n",
    "    - Selección/Reducción de variables.\n",
    "3. Modelo: (Conjunto Entrenamiento, Test y Validación)\n",
    "    - KNN.\n",
    "    - Regresión lógistica. (Filtros ruido TOMEK LINKS, CVCF)\n",
    "    - Arboles.\n",
    "4. Evalución: Metodologias dividir datos entrenamiento, validacion y test\n",
    "    - Matriz de confusión.\n",
    "    - Clasificacion precision predictiva(Usando Grid).\n",
    "    - Error cuadratico medio.\n",
    "5. Interpretación y difusión:\n",
    "    - Usos del modelo.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto Final\n",
    "- Yeray Aller Errea\n",
    "- Javier Aranguren Ortiz\n",
    "### Resumen\n",
    "El objetivo de nuestro grupo va a ser utilizar las distintas herramientas que nos proporciona esta asignatura para identificar que tipo de trigo es.\n",
    "\n",
    "### Desarrollo\n",
    "![Descripción KDD](KDD.jpg)  \n",
    "Para este proyeto vamos a utilizar la metodología KDD, que se divide en la siguientes etapas\n",
    "1. Integracion y recopilacion.\n",
    "2. Preprocesamiento.\n",
    "3. Modelado.\n",
    "4. Evalución.\n",
    "5. Disfusiónn.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTEGRACIÓN Y RECOPILACIÓN ##\n",
    "### Dataset ###\n",
    "Para ese proyecto hemos seleccionado el dataset [Seeds](https://www.kaggle.com/datasets/rwzhang/seeds-dataset).El conjunto de datos Seeds contiene siete atributos geométricos de granos de trigo, y hay tres variedades de trigo.\n",
    "- Área del grano **A**\n",
    "- Perímetro del grano **P**\n",
    "- Compacidad del grano **C** = 4 * pi * A / P^2\n",
    "- Longitud del núcleo\n",
    "- Ancho del núcleo\n",
    "- Coeficiente de asimetría\n",
    "- Longitud del surco del núcleo\n",
    "\n",
    "### Librerias ###\n",
    "Para el siguiente proyecto hemos usado las siguientes librerias:\n",
    "- Pandas.\n",
    "- Numpy.\n",
    "- Sekelearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importamos todas las librerias necesarias para la práctica\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos ###\n",
    "La información necesaria para este proyecto se encuentra seed_dataset.txt, la extraemos y la almacenamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimetro</th>\n",
       "      <th>compacidad</th>\n",
       "      <th>longitud_nucleo</th>\n",
       "      <th>ancho_nucleo</th>\n",
       "      <th>coeficiente_asimetria</th>\n",
       "      <th>longitud_surco</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>5.137</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.631</td>\n",
       "      <td>4.870</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>5.140</td>\n",
       "      <td>2.795</td>\n",
       "      <td>4.325</td>\n",
       "      <td>5.003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>13.20</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.232</td>\n",
       "      <td>8.315</td>\n",
       "      <td>5.056</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11.84</td>\n",
       "      <td>13.21</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>5.175</td>\n",
       "      <td>2.836</td>\n",
       "      <td>3.598</td>\n",
       "      <td>5.044</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.637</td>\n",
       "      <td>5.063</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      area  perimetro  compacidad  longitud_nucleo  ancho_nucleo  \\\n",
       "0    15.26      14.84      0.8710            5.763         3.312   \n",
       "1    14.88      14.57      0.8811            5.554         3.333   \n",
       "2    14.29      14.09      0.9050            5.291         3.337   \n",
       "3    13.84      13.94      0.8955            5.324         3.379   \n",
       "4    16.14      14.99      0.9034            5.658         3.562   \n",
       "..     ...        ...         ...              ...           ...   \n",
       "205  12.19      13.20      0.8783            5.137         2.981   \n",
       "206  11.23      12.88      0.8511            5.140         2.795   \n",
       "207  13.20      13.66      0.8883            5.236         3.232   \n",
       "208  11.84      13.21      0.8521            5.175         2.836   \n",
       "209  12.30      13.34      0.8684            5.243         2.974   \n",
       "\n",
       "     coeficiente_asimetria  longitud_surco  class  \n",
       "0                    2.221           5.220      1  \n",
       "1                    1.018           4.956      1  \n",
       "2                    2.699           4.825      1  \n",
       "3                    2.259           4.805      1  \n",
       "4                    1.355           5.175      1  \n",
       "..                     ...             ...    ...  \n",
       "205                  3.631           4.870      3  \n",
       "206                  4.325           5.003      3  \n",
       "207                  8.315           5.056      3  \n",
       "208                  3.598           5.044      3  \n",
       "209                  5.637           5.063      3  \n",
       "\n",
       "[210 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura del archivo csv\n",
    "seeds = pd.read_csv('seeds_dataset.txt', delim_whitespace=True, header=None)\n",
    "# Asignamos los nombres de las columnas\n",
    "seeds.columns = ['area', 'perimetro', 'compacidad', 'longitud_nucleo', 'ancho_nucleo', 'coeficiente_asimetria', 'longitud_surco', 'class']\n",
    "seeds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos si hay alguna fila que tenga la columna class vacia y la tratamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay clases sin valor\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def esNulo(dataset):\n",
    "    if(dataset[\"class\"].isnull().sum()==0):\n",
    "        print(\"No hay clases sin valor\")\n",
    "    else:\n",
    "        print(\"Hay clases sin valor\")\n",
    "    \n",
    "print(esNulo(seeds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos si existen duplicidades o inconsistencias y las tratamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existen duplicidades\n"
     ]
    }
   ],
   "source": [
    "if(seeds.duplicated().any()):\n",
    "    seeds.drop_duplicates()\n",
    "    print(\"Duplicidades eliminadas\")\n",
    "else:\n",
    "    print(\"No existen duplicidades\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos dos DataFrames: uno para la información de entrada (X) y otro para la de salida (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = seeds.iloc[:, :-1]\n",
    "y = seeds.iloc[:, -1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a dividir los ejemplos en train, validación y test utilizando Hold-out con estratificación y el valor 42 como semilla.\n",
    "\n",
    "Vamos a dividir los conjuntos en un 10% test, 80% entrenamiento y el restante validacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resto, X_test, y_resto, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_resto, y_resto, test_size=0.2, stratify=y_resto, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la clase de detección y tratamiento de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierDetecion_treatment_IQR(TransformerMixin):\n",
    "\n",
    "    # Constructor de la clase\n",
    "    def __init__(self, k=1.5, columns=None):\n",
    "        self.k = k\n",
    "        self.columns = columns\n",
    "    \n",
    "    # Método fit\n",
    "    def fit(self, X, y=None):\n",
    "        # Transformamos X a DataFrame por si llega un array de Numpy (para compatibilidad en la Pipeline)\n",
    "        X = pd.DataFrame(X)\n",
    "        if self.columns == None:\n",
    "            # Si no se determinan variables en el constructor si tratan todas\n",
    "            self.columns = X.columns\n",
    "            #self.stats = <RELLENAR>\n",
    "            self.stats = X.describe()\n",
    "        # Devolvemos el propio objeto modificado\n",
    "        return self\n",
    "\n",
    "    # Método transform\n",
    "    def transform(self, X):\n",
    "        # Transformamos X a DataFrame por si llega un array de Numpy (para compatibilidad en la Pipeline)\n",
    "        X = pd.DataFrame(X)\n",
    "        # Creamos una copia del DataFrame X para no perder los datos originales\n",
    "        Xaux = X.copy()\n",
    "        # Se calula el IQR de cada variable\n",
    "        IQRs = self.stats.loc['75%'] - self.stats.loc['25%']\n",
    "        # Se calculan los límites inferiores y superiores   \n",
    "        limiteInf = self.stats.loc['25%'] - self.k * IQRs\n",
    "        limiteSup = self.stats.loc['75%'] + self.k * IQRs\n",
    "        # Se comprueba qué elementos están por encima y por debajo de dichos límites (máscaras de booleanos)  \n",
    "        menores = (X < limiteInf)\n",
    "        mayores = (X > limiteSup)\n",
    "        # Se recorren las variables para detectar outliers y tratarlos (sustituir por la mediana de la variable)\n",
    "        for c in self.columns:\n",
    "            # obtenemos la lista de booleanos correspondientes a si los valores de los ejemplos son outliers o no para la variable c\n",
    "            indices = np.logical_or(menores[c], mayores[c])\n",
    "            # Si hay outliers\n",
    "            if indices.any():\n",
    "                # Los sustituimos por la mediana\n",
    "                Xaux.loc[indices,c] = self.stats.loc['50%',c]\n",
    "        # Se devuelve el DataFrame modificado\n",
    "        return Xaux\n",
    "    \n",
    "    # Método para asignar los valores de los híper-parámetros y que, de este modo, \n",
    "        # podamos aplicar GridSearchCV sobre un objeto de esta clase\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    # Método para obtener los valores de los híper-parámetros que queramos del modelo (lo usa GridSearchCV al mostrar la mejor configuración)\n",
    "    def get_params(self, deep=True):\n",
    "        # Devolvemos los valores de los híper-parámetros del método de preparación de datos\n",
    "        return {\"k\": self.k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se han encontrado outliers\n"
     ]
    }
   ],
   "source": [
    "out_IQR = OutlierDetecion_treatment_IQR(k=3)\n",
    "X_train_IQR = out_IQR.fit_transform(X_train)\n",
    "if(X_train.equals(X_train_IQR)):\n",
    "   print(\"No se han encontrado outliers\")\n",
    "else:\n",
    "   print(\"Se han encontrado outliers y el dataframe ha sido modificado\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a utilizar diferentes tecnicas de clasificacion para evaluar sus rendimientos.\n",
    "### KNN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'n_neighbors': 5, 'p': 1.5, 'weights': 'distance'}\n",
      "Best score: 95.40%\n",
      "Precisión: 85.71%\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2, 1.5, 3]\n",
    "}\n",
    "\n",
    "grid_KNN = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
    "grid_KNN.fit(X_train, y_train)\n",
    "prediccion_KNN = grid_KNN.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, prediccion_KNN) * 100\n",
    "\n",
    "print(\"Mejores hiperparámetros:\", grid_KNN.best_params_)\n",
    "print(\"Best score: {:.2f}%\".format(grid_KNN.best_score_ * 100))\n",
    "print(\"Precisión: {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(3)\n",
    "knn.fit(X_train, y_train)\n",
    "prediccion_KNN2 = knn.predict(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 90.48%\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "prediccion = lr.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, prediccion) * 100\n",
    "print(\"Precisión: {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arboles de decision ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del árbol de decisión: 95.24%\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "prediccion_arbol = tree.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, prediccion_arbol) * 100\n",
    "print('Precisión del árbol de decisión: {:.2f}%'.format(accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusión ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51  0  0]\n",
      " [ 0 50  0]\n",
      " [ 0  0 50]]\n",
      "[[47  2  2]\n",
      " [ 3 47  0]\n",
      " [ 2  0 48]]\n",
      "[[51  0  0]\n",
      " [ 0 50  0]\n",
      " [ 0  0 50]]\n"
     ]
    }
   ],
   "source": [
    "def obtenerMatrizConfusion(clasificador, X, y, labels):\n",
    "    predicciones = clasificador.predict(X)\n",
    "    return confusion_matrix(y, predicciones, labels=labels)\n",
    "# Creo un clasificador que siempre clasifique negativo\n",
    "matrizConfusionKNN = obtenerMatrizConfusion(grid_KNN, X_train, y_train, labels=[1,2,3])\n",
    "matrizConfusionLR = obtenerMatrizConfusion(lr, X_train, y_train, labels=[1,2,3])\n",
    "matrizConfusionTREE = obtenerMatrizConfusion(tree, X_train, y_train, labels=[1,2,3])\n",
    "print(matrizConfusionKNN)\n",
    "print(matrizConfusionLR)\n",
    "print(matrizConfusionTREE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
